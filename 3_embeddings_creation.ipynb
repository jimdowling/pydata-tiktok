{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "877c805b",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üë®üèª‚Äçüè´ Build Index </span>\n",
    "\n",
    "In this notebook you will create a feature group for your candidate embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c73384",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üìù Imports </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1de52446",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-20 09:05:37.293545: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-20 09:05:37.294754: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-20 09:05:37.319359: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-20 09:05:37.320658: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-20 09:05:37.909777: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a16d07e",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üîÆ Connect to Hopsworks Feature Store </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db9577ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/17565\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login()\n",
    "\n",
    "fs = project.get_feature_store()\n",
    "mr = project.get_model_registry()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52e31c6",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üéØ Compute Candidate Embeddings </span>\n",
    "\n",
    "You start by computing candidate embeddings for all items in the training data.\n",
    "\n",
    "First, you load your candidate model. Recall that you uploaded it to the Hopsworks Model Registry in the previous notebook. If you don't have the model locally you can download it from the Model Registry using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e88fc86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model artifact (2 dirs, 6 files)... DONE\r"
     ]
    }
   ],
   "source": [
    "model = mr.get_model(\n",
    "    name=\"candidate_model\",\n",
    "    version=1,\n",
    ")\n",
    "model_path = model.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dccd0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-20 09:05:45.732388: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:03:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-20 09:05:45.732696: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "candidate_model = tf.saved_model.load(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec603fb",
   "metadata": {},
   "source": [
    "Next you compute the embeddings of all candidate videos that were used to train the retrieval model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15b25479",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_view = fs.get_feature_view(\n",
    "    name=\"retrieval\",\n",
    "    version=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f9dc797",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/arrow/cpp/src/arrow/status.cc:137: DoAction result was not fully consumed: Cancelled: Flight cancelled call, with message: CANCELLED. Detail: Cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using ArrowFlight (72.76s) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "VersionWarning: Incremented version to `2`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>interaction_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>country</th>\n",
       "      <th>video_id</th>\n",
       "      <th>category</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>video_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2124-02-0249</td>\n",
       "      <td>SW104K</td>\n",
       "      <td>Female</td>\n",
       "      <td>44</td>\n",
       "      <td>Wallis &amp; Futuna</td>\n",
       "      <td>5QM85J</td>\n",
       "      <td>Education</td>\n",
       "      <td>11410</td>\n",
       "      <td>8493</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0405-17-5906</td>\n",
       "      <td>RA693D</td>\n",
       "      <td>Male</td>\n",
       "      <td>80</td>\n",
       "      <td>Tunisia</td>\n",
       "      <td>2RS24G</td>\n",
       "      <td>Education</td>\n",
       "      <td>328257</td>\n",
       "      <td>7209</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6376-81-3106</td>\n",
       "      <td>HN430K</td>\n",
       "      <td>Other</td>\n",
       "      <td>34</td>\n",
       "      <td>Martinique</td>\n",
       "      <td>9KL68J</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>107043</td>\n",
       "      <td>30277</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  interaction_id user_id  gender  age          country video_id  \\\n",
       "0   2124-02-0249  SW104K  Female   44  Wallis & Futuna   5QM85J   \n",
       "1   0405-17-5906  RA693D    Male   80          Tunisia   2RS24G   \n",
       "2   6376-81-3106  HN430K   Other   34       Martinique   9KL68J   \n",
       "\n",
       "        category   views  likes  video_length  \n",
       "0      Education   11410   8493            51  \n",
       "1      Education  328257   7209            70  \n",
       "2  Entertainment  107043  30277           126  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, val_df, test_df, _, _, _ = feature_view.train_validation_test_split(\n",
    "    validation_size=0.1, \n",
    "    test_size=0.1,\n",
    "    description='Retrieval dataset splits',\n",
    ")\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf72c728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>category</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>video_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5QM85J</td>\n",
       "      <td>Education</td>\n",
       "      <td>11410</td>\n",
       "      <td>8493</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2RS24G</td>\n",
       "      <td>Education</td>\n",
       "      <td>328257</td>\n",
       "      <td>7209</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9KL68J</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>107043</td>\n",
       "      <td>30277</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  video_id       category   views  likes  video_length\n",
       "0   5QM85J      Education   11410   8493            51\n",
       "1   2RS24G      Education  328257   7209            70\n",
       "2   9KL68J  Entertainment  107043  30277           126"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the list of input features for the candidate model from the model schema\n",
    "model_schema = model.model_schema['input_schema']['columnar_schema']\n",
    "candidate_features = [feat['name'] for feat in model_schema]\n",
    "\n",
    "# Select the candidate features from the training DataFrame\n",
    "item_df = train_df[candidate_features]\n",
    "\n",
    "# Drop duplicate rows based on the 'article_id' column to get unique candidate items\n",
    "item_df.drop_duplicates(subset=\"video_id\", inplace=True)\n",
    "\n",
    "item_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6a8d2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TensorFlow dataset from the item DataFrame\n",
    "item_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    {col: item_df[col] for col in item_df})\n",
    "\n",
    "# Compute embeddings for all candidate items using the candidate_model\n",
    "candidate_embeddings = item_ds.batch(2048).map(\n",
    "    lambda x: (x[\"video_id\"], candidate_model(x))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57b95ca",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">‚öôÔ∏è Data Preparation </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47d30dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all article IDs and embeddings from the candidate_embeddings dataset\n",
    "all_article_ids = tf.concat([batch[0] for batch in candidate_embeddings], axis=0)\n",
    "all_embeddings = tf.concat([batch[1] for batch in candidate_embeddings], axis=0)\n",
    "\n",
    "# Convert tensors to numpy arrays\n",
    "all_article_ids_np = all_article_ids.numpy()\n",
    "all_embeddings_np = all_embeddings.numpy()\n",
    "\n",
    "# Convert numpy arrays to lists\n",
    "items_ids_list = all_article_ids_np.tolist()\n",
    "embeddings_list = all_embeddings_np.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c311309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5QM85J</td>\n",
       "      <td>[-0.12486518919467926, -0.7023744583129883, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2RS24G</td>\n",
       "      <td>[-742.2847290039062, -706.9532470703125, -155....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9KL68J</td>\n",
       "      <td>[-0.12486518919467926, -0.7023744583129883, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7JK11F</td>\n",
       "      <td>[-0.12486518919467926, -0.7023744583129883, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3TW96L</td>\n",
       "      <td>[-10.557537078857422, -10.630267143249512, -1....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  video_id                                         embeddings\n",
       "0   5QM85J  [-0.12486518919467926, -0.7023744583129883, 0....\n",
       "1   2RS24G  [-742.2847290039062, -706.9532470703125, -155....\n",
       "2   9KL68J  [-0.12486518919467926, -0.7023744583129883, 0....\n",
       "3   7JK11F  [-0.12486518919467926, -0.7023744583129883, 0....\n",
       "4   3TW96L  [-10.557537078857422, -10.630267143249512, -1...."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame\n",
    "data_emb = pd.DataFrame({\n",
    "    'video_id': items_ids_list, \n",
    "    'embeddings': embeddings_list,\n",
    "})\n",
    "data_emb['video_id'] = data_emb['video_id'].str.decode('utf-8')\n",
    "\n",
    "data_emb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84b6dfc",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">ü™Ñ Feature Group Creation </span>\n",
    "\n",
    "Now you are ready to create a feature group for your candidate embeddings.\n",
    "\n",
    "To begin with, you need to create your Embedding Index where you will specify the name of the embeddings feature and the embeddings length.\n",
    "Then you attach this index to the FG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50c3da55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hsfs import embedding\n",
    "\n",
    "# Create the Embedding Index\n",
    "emb = embedding.EmbeddingIndex()\n",
    "\n",
    "emb.add_embedding(\n",
    "    \"embeddings\",                           # Embeddings feature name\n",
    "    len(data_emb[\"embeddings\"].iloc[0]),    # Embeddings length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20644b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeprecationWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/17565/fs/17485/fg/737611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Rows 24982/24982 | Elapsed Time: 00:09 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: candidate_embeddings_fg_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/17565/jobs/named/candidate_embeddings_fg_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<hsfs.core.job.Job at 0x7f9ec034b5b0>, None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get or create the 'candidate_embeddings_fg' feature group\n",
    "candidate_embeddings_fg = fs.get_or_create_feature_group(\n",
    "    name=\"candidate_embeddings_fg\",\n",
    "    embedding_index=emb,                    # Specify the Embedding Index\n",
    "    primary_key=['video_id'],\n",
    "    version=1,\n",
    "    description='Embeddings for each video',\n",
    "    online_enabled=True,\n",
    ")\n",
    "\n",
    "candidate_embeddings_fg.insert(data_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074d7f1a",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">ü™Ñ Feature View Creation </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb1a3620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature view created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/17565/fs/17485/fv/candidate_embeddings/version/1\n"
     ]
    }
   ],
   "source": [
    "# Get or create the 'candidate_embeddings' feature view\n",
    "feature_view = fs.get_or_create_feature_view(\n",
    "    name=\"candidate_embeddings\",\n",
    "    version=1,\n",
    "    description='Embeddings of each article',\n",
    "    query=candidate_embeddings_fg.select([\"video_id\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb25aae0",
   "metadata": {},
   "source": [
    "---\n",
    "## <span style=\"color:#ff5f27\">‚è©Ô∏è Next Steps </span>\n",
    "\n",
    "At this point you have a recommender system that is able to generate a set of candidate videos for a user. However, many of these could be poor, as the candidate model was trained with only a few subset of the features. In the next notebook, you'll create a ranking dataset to train a *ranking model* to do more fine-grained predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
