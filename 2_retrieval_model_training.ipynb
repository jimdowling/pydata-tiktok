{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f53a397",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üß¨ Train Retrieval Model </span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faa182c",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üìù Imports </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91d80acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import StringLookup, Normalization\n",
    "import tensorflow_recommenders as tfrs\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09283b4",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üîÆ Connect to Hopsworks Feature Store </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03b4ad6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/17565\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "\n",
    "project = hopsworks.login()\n",
    "\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3261b352",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üî™ Feature Selection </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c149d5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_fg = fs.get_feature_group(\n",
    "    name=\"users\",\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "videos_fg = fs.get_feature_group(\n",
    "    name=\"videos\",\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "interactions_fg = fs.get_feature_group(\n",
    "    name=\"interactions\",\n",
    "    version=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2c14e9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "272dc061",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m obs \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[0;32m----> 2\u001b[0m     [[\u001b[43mgeneric\u001b[49m\u001b[38;5;241m.\u001b[39mperson\u001b[38;5;241m.\u001b[39midentifier(mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m####-##-####\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlike\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWA546S\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3EL60S\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m206\u001b[39m]],\n\u001b[1;32m      3\u001b[0m     columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minteraction_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minteraction_type\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwatch_time\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m obs\n",
      "\u001b[0;31mNameError\u001b[0m: name 'generic' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "obs = pd.DataFrame(\n",
    "    [[generic.person.identifier(mask='####-##-####'), 'like', 'WA546S', '3EL60S', 206]],\n",
    "    columns=['interaction_id', 'interaction_type', 'user_id', 'video_id', 'watch_time']\n",
    ")\n",
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29c2fbeb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'obs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m interactions_fg\u001b[38;5;241m.\u001b[39minsert(\u001b[43mobs\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'obs' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "interactions_fg.insert(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a22d99",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d72398e",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_FEATURES = [\"user_id\", \"gender\", \"age\", \"country\"]\n",
    "CANDIDATE_FEATURES = [\"video_id\", \"category\", \"views\", \"likes\", \"video_length\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f091291d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/arrow/cpp/src/arrow/status.cc:137: DoAction result was not fully consumed: Cancelled: Flight cancelled call, with message: CANCELLED. Detail: Cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using ArrowFlight (74.19s) \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>interaction_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>country</th>\n",
       "      <th>video_id</th>\n",
       "      <th>category</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>video_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2124-02-0249</td>\n",
       "      <td>SW104K</td>\n",
       "      <td>Female</td>\n",
       "      <td>44</td>\n",
       "      <td>Wallis &amp; Futuna</td>\n",
       "      <td>5QM85J</td>\n",
       "      <td>Education</td>\n",
       "      <td>11410</td>\n",
       "      <td>8493</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0405-17-5906</td>\n",
       "      <td>RA693D</td>\n",
       "      <td>Male</td>\n",
       "      <td>80</td>\n",
       "      <td>Tunisia</td>\n",
       "      <td>2RS24G</td>\n",
       "      <td>Education</td>\n",
       "      <td>328257</td>\n",
       "      <td>7209</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6376-81-3106</td>\n",
       "      <td>HN430K</td>\n",
       "      <td>Other</td>\n",
       "      <td>34</td>\n",
       "      <td>Martinique</td>\n",
       "      <td>9KL68J</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>107043</td>\n",
       "      <td>30277</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3515-04-4058</td>\n",
       "      <td>DR282A</td>\n",
       "      <td>Female</td>\n",
       "      <td>64</td>\n",
       "      <td>Greenland</td>\n",
       "      <td>7JK11F</td>\n",
       "      <td>Travel</td>\n",
       "      <td>205092</td>\n",
       "      <td>131719</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3167-11-9736</td>\n",
       "      <td>KK401R</td>\n",
       "      <td>Female</td>\n",
       "      <td>64</td>\n",
       "      <td>Congo - Brazzaville</td>\n",
       "      <td>3TW96L</td>\n",
       "      <td>Education</td>\n",
       "      <td>35733</td>\n",
       "      <td>1825</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  interaction_id user_id  gender  age              country video_id  \\\n",
       "0   2124-02-0249  SW104K  Female   44      Wallis & Futuna   5QM85J   \n",
       "1   0405-17-5906  RA693D    Male   80              Tunisia   2RS24G   \n",
       "2   6376-81-3106  HN430K   Other   34           Martinique   9KL68J   \n",
       "3   3515-04-4058  DR282A  Female   64            Greenland   7JK11F   \n",
       "4   3167-11-9736  KK401R  Female   64  Congo - Brazzaville   3TW96L   \n",
       "\n",
       "        category   views   likes  video_length  \n",
       "0      Education   11410    8493            51  \n",
       "1      Education  328257    7209            70  \n",
       "2  Entertainment  107043   30277           126  \n",
       "3         Travel  205092  131719            79  \n",
       "4      Education   35733    1825           245  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select features for training data\n",
    "selected_features = interactions_fg.select([\"interaction_id\"])\\\n",
    "    .join(users_fg.select(QUERY_FEATURES), on=\"user_id\")\\\n",
    "    .join(videos_fg.select(CANDIDATE_FEATURES), on=\"video_id\")\n",
    "\n",
    "# Uncomment this if you would like to view your selected features\n",
    "# selected_features.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87707f44",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">‚öôÔ∏è Feature View Creation </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af97a264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature view created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/17565/fs/17485/fv/retrieval/version/1\n"
     ]
    }
   ],
   "source": [
    "feature_view = fs.get_or_create_feature_view(\n",
    "    name='retrieval',\n",
    "    version=1,\n",
    "    query=selected_features,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad1dc1f",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üèãÔ∏è Training Dataset </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "437f3034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using ArrowFlight (71.81s) \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>interaction_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>country</th>\n",
       "      <th>video_id</th>\n",
       "      <th>category</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>video_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0405-17-5906</td>\n",
       "      <td>RA693D</td>\n",
       "      <td>Male</td>\n",
       "      <td>80</td>\n",
       "      <td>Tunisia</td>\n",
       "      <td>2RS24G</td>\n",
       "      <td>Education</td>\n",
       "      <td>328257</td>\n",
       "      <td>7209</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6376-81-3106</td>\n",
       "      <td>HN430K</td>\n",
       "      <td>Other</td>\n",
       "      <td>34</td>\n",
       "      <td>Martinique</td>\n",
       "      <td>9KL68J</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>107043</td>\n",
       "      <td>30277</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3167-11-9736</td>\n",
       "      <td>KK401R</td>\n",
       "      <td>Female</td>\n",
       "      <td>64</td>\n",
       "      <td>Congo - Brazzaville</td>\n",
       "      <td>3TW96L</td>\n",
       "      <td>Education</td>\n",
       "      <td>35733</td>\n",
       "      <td>1825</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  interaction_id user_id  gender  age              country video_id  \\\n",
       "1   0405-17-5906  RA693D    Male   80              Tunisia   2RS24G   \n",
       "2   6376-81-3106  HN430K   Other   34           Martinique   9KL68J   \n",
       "4   3167-11-9736  KK401R  Female   64  Congo - Brazzaville   3TW96L   \n",
       "\n",
       "        category   views  likes  video_length  \n",
       "1      Education  328257   7209            70  \n",
       "2  Entertainment  107043  30277           126  \n",
       "4      Education   35733   1825           245  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, val_df, test_df, _, _, _ = feature_view.train_validation_test_split(\n",
    "    validation_size=0.1, \n",
    "    test_size=0.1,\n",
    "    description='Retrieval dataset splits',\n",
    ")\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66935588",
   "metadata": {},
   "source": [
    "You will train your retrieval model with a subset of features.\n",
    "\n",
    "For the query embedding you will use:\n",
    "- `user_id`: ID of a user.\n",
    "- `gender`: Gender of a user.\n",
    "- `age`: age of a user.\n",
    "- `country`: country if a user.\n",
    "\n",
    "For the candidate embedding you will use:\n",
    "- `video_id`: ID of a video.\n",
    "- `category`: Video Category.\n",
    "- `views`: Number of video views.\n",
    "- `likes`: Number of video likes.\n",
    "- `video_length`: Length of video.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f95d63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-20 08:59:22.576899: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:03:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-20 08:59:22.577368: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "def df_to_ds(df):\n",
    "    return tf.data.Dataset.from_tensor_slices({col: df[col] for col in df})\n",
    "\n",
    "BATCH_SIZE = 2048\n",
    "train_ds = df_to_ds(train_df).batch(BATCH_SIZE).cache().shuffle(BATCH_SIZE*10)\n",
    "val_ds = df_to_ds(val_df).batch(BATCH_SIZE).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0bb3dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚õ≥Ô∏è Number of users: 24984\n",
      "‚õ≥Ô∏è Number of items: 24982\n"
     ]
    }
   ],
   "source": [
    "# Query Features \n",
    "user_id_list = train_df[\"user_id\"].unique().tolist()\n",
    "countries_list = train_df[\"country\"].unique().tolist()\n",
    "gender_list = train_df[\"gender\"].unique().tolist()\n",
    "\n",
    "# Item Features\n",
    "video_id_list = train_df[\"video_id\"].unique().tolist()\n",
    "category_list = train_df[\"category\"].unique().tolist()\n",
    "\n",
    "print(f\"‚õ≥Ô∏è Number of users: {len(user_id_list)}\")\n",
    "print(f\"‚õ≥Ô∏è Number of items: {len(video_id_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434c4058",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üè∞ Two Tower Model </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8db71a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_DIM = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63b6462f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 16), dtype=float32, numpy=\n",
       "array([[-0.13735218,  0.21536459, -0.22964887,  0.14158446, -0.00432214,\n",
       "        -0.1594676 , -0.3131661 ,  0.21178053,  0.19285168, -0.07733099,\n",
       "        -0.03732955,  0.14767246, -0.07962313,  0.03984793,  0.08218176,\n",
       "        -0.09402015]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class QueryTower(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.emb_dim = EMB_DIM\n",
    "        self.user_embedding = tf.keras.Sequential([\n",
    "            StringLookup(\n",
    "                vocabulary=user_id_list,\n",
    "                mask_token=None\n",
    "            ),\n",
    "            tf.keras.layers.Embedding(\n",
    "                # You add an additional embedding to account for unknown tokens.\n",
    "                len(user_id_list) + 1,\n",
    "                self.emb_dim\n",
    "            )\n",
    "        ])\n",
    "\n",
    "        self.normalized_age = Normalization(axis=None)\n",
    "        \n",
    "        # Converts strings into integer indices (scikit-learn LabelEncoder analog)\n",
    "        self.gender_tokenizer = StringLookup(\n",
    "            vocabulary=gender_list,\n",
    "            mask_token=None,\n",
    "        )\n",
    "        \n",
    "        self.country_tokenizer = StringLookup(\n",
    "            vocabulary=countries_list, \n",
    "            mask_token=None,\n",
    "        )\n",
    "\n",
    "        self.fnn = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(self.emb_dim, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(self.emb_dim)\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        gender_embedding = tf.one_hot(\n",
    "            self.gender_tokenizer(inputs[\"gender\"]),\n",
    "            len(gender_list),\n",
    "        )\n",
    "        \n",
    "        country_embedding = tf.one_hot(\n",
    "            self.country_tokenizer(inputs[\"country\"]),\n",
    "            len(countries_list),\n",
    "        )\n",
    "        \n",
    "        concatenated_inputs = tf.concat([\n",
    "            self.user_embedding(inputs[\"user_id\"]),\n",
    "            tf.reshape(self.normalized_age(inputs[\"age\"]), (-1,1)),\n",
    "            gender_embedding,\n",
    "            country_embedding,\n",
    "        ], axis=1)\n",
    "\n",
    "        outputs = self.fnn(concatenated_inputs)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "query_model = QueryTower()\n",
    "\n",
    "query_model.normalized_age.adapt(train_ds.map(lambda x : x[\"age\"]))\n",
    "\n",
    "# Initialize model with inputs.\n",
    "query_df = train_df[QUERY_FEATURES]\n",
    "query_ds = df_to_ds(query_df).batch(1)\n",
    "query_model(next(iter(query_ds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04965563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 16), dtype=float32, numpy=\n",
       "array([[ -31187.38 ,  -78264.82 ,   44769.7  ,   94622.984,  -71976.43 ,\n",
       "          12868.637,   22664.69 ,   55032.91 , -162128.47 ,  -62499.402,\n",
       "          55290.12 ,   43989.24 ,  -24987.719,   73449.43 ,  -85819.74 ,\n",
       "          53954.434]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ItemTower(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.emb_dim = EMB_DIM\n",
    "        self.video_embedding = tf.keras.Sequential([\n",
    "            StringLookup(\n",
    "                vocabulary=video_id_list,\n",
    "                mask_token=None\n",
    "            ),\n",
    "            tf.keras.layers.Embedding(\n",
    "                # You add an additional embedding to account for unknown tokens.\n",
    "                len(video_id_list) + 1,\n",
    "                self.emb_dim,\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        # Converts strings into integer indices (scikit-learn LabelEncoder analog)\n",
    "        self.category_tokenizer = StringLookup(\n",
    "            vocabulary=category_list, \n",
    "            mask_token=None,\n",
    "        )\n",
    "        \n",
    "        self.normalized_views = Normalization(axis=None)\n",
    "        self.normalized_likes = Normalization(axis=None)\n",
    "        self.normalized_video_length = Normalization(axis=None)\n",
    "\n",
    "        self.fnn = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(self.emb_dim, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(self.emb_dim)\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        category_embedding = tf.one_hot(\n",
    "            self.category_tokenizer(inputs[\"category\"]),\n",
    "            len(category_list),\n",
    "        )\n",
    "\n",
    "        concatenated_inputs = tf.concat([\n",
    "            self.video_embedding(inputs[\"video_id\"]),\n",
    "            category_embedding,\n",
    "            tf.reshape(self.normalized_views(inputs[\"views\"]), (-1,1)),\n",
    "            tf.reshape(self.normalized_views(inputs[\"likes\"]), (-1,1)),\n",
    "            tf.reshape(self.normalized_views(inputs[\"video_length\"]), (-1,1)),\n",
    "        ], axis=1)\n",
    "\n",
    "        outputs = self.fnn(concatenated_inputs)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    \n",
    "item_model = ItemTower()\n",
    "\n",
    "item_df = train_df[CANDIDATE_FEATURES]\n",
    "item_df.drop_duplicates(subset=\"video_id\", inplace=True)\n",
    "item_ds = df_to_ds(item_df)\n",
    "\n",
    "item_model(next(iter(item_ds.batch(1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "440193f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoTowerModel(tf.keras.Model):\n",
    "    def __init__(self, query_model, item_model):\n",
    "        super().__init__()\n",
    "        self.query_model = query_model\n",
    "        self.item_model = item_model\n",
    "        self.task = tfrs.tasks.Retrieval(\n",
    "            metrics=tfrs.metrics.FactorizedTopK(\n",
    "                candidates=item_ds.batch(BATCH_SIZE).map(self.item_model)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def train_step(self, batch) -> tf.Tensor:\n",
    "        # Set up a gradient tape to record gradients.\n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "            # Loss computation.\n",
    "            user_embeddings = self.query_model(batch)\n",
    "            item_embeddings = self.item_model(batch)\n",
    "            loss = self.task(\n",
    "                user_embeddings, \n",
    "                item_embeddings,\n",
    "                compute_metrics=False,\n",
    "            )\n",
    "\n",
    "            # Handle regularization losses as well.\n",
    "            regularization_loss = sum(self.losses)\n",
    "\n",
    "            total_loss = loss + regularization_loss\n",
    "\n",
    "        gradients = tape.gradient(total_loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "\n",
    "        metrics = {\n",
    "            \"loss\": loss,\n",
    "            \"regularization_loss\": regularization_loss,\n",
    "            \"total_loss\": total_loss\n",
    "        }\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    def test_step(self, batch) -> tf.Tensor:\n",
    "        # Loss computation.\n",
    "        user_embeddings = self.query_model(batch)\n",
    "        item_embeddings = self.item_model(batch)\n",
    "\n",
    "        loss = self.task(\n",
    "            user_embeddings, \n",
    "            item_embeddings,\n",
    "            compute_metrics=False,\n",
    "        )\n",
    "\n",
    "        # Handle regularization losses as well.\n",
    "        regularization_loss = sum(self.losses)\n",
    "\n",
    "        total_loss = loss + regularization_loss\n",
    "\n",
    "        metrics = {metric.name: metric.result() for metric in self.metrics}\n",
    "        metrics[\"loss\"] = loss\n",
    "        metrics[\"regularization_loss\"] = regularization_loss\n",
    "        metrics[\"total_loss\"] = total_loss\n",
    "\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf66678",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27\">üèÉüèª‚Äç‚ôÇÔ∏è Model Training </span>\n",
    "\n",
    "You'll train our model using the AdamW optimizer, which applies weight regularization during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e96e26c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TwoTowerModel with the specified query_model and item_model\n",
    "model = TwoTowerModel(query_model, item_model)\n",
    "\n",
    "# Define an optimizer using AdamW with a learning rate of 0.01\n",
    "optimizer = tf.keras.optimizers.AdamW(\n",
    "    weight_decay=0.001, \n",
    "    learning_rate=0.01,\n",
    ")\n",
    "\n",
    "# Compile the model using the specified optimizer\n",
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46ea848e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "391/391 [==============================] - 22s 53ms/step - loss: 573137.7862 - regularization_loss: 0.0000e+00 - total_loss: 573137.7862 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 19123.7344 - val_regularization_loss: 0.0000e+00 - val_total_loss: 19123.7344\n",
      "Epoch 2/5\n",
      "391/391 [==============================] - 24s 62ms/step - loss: 15943.9660 - regularization_loss: 0.0000e+00 - total_loss: 15943.9660 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 12643.1133 - val_regularization_loss: 0.0000e+00 - val_total_loss: 12643.1133\n",
      "Epoch 3/5\n",
      "391/391 [==============================] - 24s 61ms/step - loss: 15616.3456 - regularization_loss: 0.0000e+00 - total_loss: 15616.3456 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 12631.0039 - val_regularization_loss: 0.0000e+00 - val_total_loss: 12631.0039\n",
      "Epoch 4/5\n",
      "391/391 [==============================] - 26s 65ms/step - loss: 15609.0583 - regularization_loss: 0.0000e+00 - total_loss: 15609.0583 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 12615.2158 - val_regularization_loss: 0.0000e+00 - val_total_loss: 12615.2158\n",
      "Epoch 5/5\n",
      "391/391 [==============================] - 35s 90ms/step - loss: 222852.5117 - regularization_loss: 0.0000e+00 - total_loss: 222852.5117 - val_factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - val_factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - val_loss: 12685.8457 - val_regularization_loss: 0.0000e+00 - val_total_loss: 12685.8457\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f36ddb42140>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_ds, \n",
    "    validation_data=val_ds, \n",
    "    epochs=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb20b1e",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27\">üóÑÔ∏è Upload Model to Model Registry </span>\n",
    "\n",
    "One of the features in Hopsworks is the model registry. This is where you can store different versions of models and compare their performance. Models from the registry can then be served as API endpoints.\n",
    "\n",
    "Let's connect to the model registry using the [HSML library](https://docs.hopsworks.ai/machine-learning-api/latest) from Hopsworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aac5bd7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "mr = project.get_model_registry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e3fe643",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryModelModule(tf.Module):\n",
    "    def __init__(self, query_model):\n",
    "        self.query_model = query_model\n",
    "\n",
    "    @tf.function()\n",
    "    def compute_emb(self, instances):\n",
    "        query_emb = self.query_model(instances)\n",
    "        return {\n",
    "            \"user_id\": instances[\"user_id\"],\n",
    "            \"gender\": instances[\"gender\"],\n",
    "            \"age\": instances[\"age\"],\n",
    "            \"country\": instances[\"country\"],\n",
    "            \"query_emb\": query_emb,\n",
    "        }\n",
    "\n",
    "# wrap query_model:   query_model -> query_model_module\n",
    "query_model = QueryModelModule(model.query_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49a54c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: query_model/assets\n",
      "INFO:tensorflow:Assets written to: query_model/assets\n"
     ]
    }
   ],
   "source": [
    "# Define the input specifications for the instances\n",
    "instances_spec = {\n",
    "    'user_id': tf.TensorSpec(shape=(None,), dtype=tf.string, name='user_id'),   # Specification for user IDs\n",
    "    'gender': tf.TensorSpec(shape=(None,), dtype=tf.string, name='gender'),     # Specification for gender\n",
    "    'country': tf.TensorSpec(shape=(None,), dtype=tf.string, name='country'),    # Specification for country\n",
    "    'age': tf.TensorSpec(shape=(None,), dtype=tf.int64, name='age'),              # Specification for age\n",
    "}\n",
    "\n",
    "# Get the concrete function for the query_model's compute_emb function using the specified input signatures\n",
    "signatures = query_model.compute_emb.get_concrete_function(instances_spec)\n",
    "\n",
    "# Save the query_model along with the concrete function signatures\n",
    "tf.saved_model.save(\n",
    "    query_model,           # The model to save\n",
    "    \"query_model\",         # Path to save the model\n",
    "    signatures=signatures, # Concrete function signatures to include\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ed39777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.preprocessing.normalization.Normalization object at 0x7f36796289a0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.preprocessing.normalization.Normalization object at 0x7f367962b640>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.preprocessing.normalization.Normalization object at 0x7f36796289a0>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.preprocessing.normalization.Normalization object at 0x7f367962b640>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: candidate_model/assets\n",
      "INFO:tensorflow:Assets written to: candidate_model/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(\n",
    "    model.item_model,    # The model to save\n",
    "    \"candidate_model\",   # Path to save the model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "baa9ce26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_schema': {'columnar_schema': [{'name': 'user_id', 'type': 'object'},\n",
       "   {'name': 'gender', 'type': 'object'},\n",
       "   {'name': 'age', 'type': 'int64'},\n",
       "   {'name': 'country', 'type': 'object'}]},\n",
       " 'output_schema': {'tensor_schema': [{'name': 'query_embedding',\n",
       "    'shape': '[16]',\n",
       "    'type': 'float32'}]}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hsml.schema import Schema\n",
    "from hsml.model_schema import ModelSchema\n",
    "\n",
    "# Infer input schema from data.\n",
    "query_model_input_schema = Schema(query_df)\n",
    "\n",
    "# Manually specify output schema.\n",
    "query_model_output_schema = Schema([{\n",
    "    \"name\": \"query_embedding\",\n",
    "    \"type\": \"float32\",\n",
    "    \"shape\": [EMB_DIM],\n",
    "}])\n",
    "\n",
    "query_model_schema = ModelSchema(\n",
    "    input_schema=query_model_input_schema,\n",
    "    output_schema=query_model_output_schema,\n",
    ")\n",
    "\n",
    "query_model_schema.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "013612bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading model files (2 dirs, 0 files):  17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                           | 1/6 [00:00<00:01,  3.01it/s]\n",
      "Uploading: 0.000%|                                                                                                                 | 0/546062 elapsed<00:00 remaining<?\u001b[A\n",
      "Uploading: 100.000%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 546062/546062 elapsed<00:02 remaining<00:00\u001b[A\n",
      "Uploading model files (2 dirs, 1 files):  17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                           | 1/6 [00:03<00:01,  3.01it/s]\n",
      "Uploading: 0.000%|                                                                                                                     | 0/57 elapsed<00:00 remaining<?\u001b[A\n",
      "Uploading: 100.000%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57/57 elapsed<00:01 remaining<00:00\u001b[A\n",
      "Uploading model files (2 dirs, 2 files):  17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                           | 1/6 [00:04<00:01,  3.01it/s]\n",
      "Uploading: 0.000%|                                                                                                                    | 0/576 elapsed<00:00 remaining<?\u001b[A\n",
      "Uploading: 100.000%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 576/576 elapsed<00:01 remaining<00:00\u001b[A\n",
      "Uploading model files (2 dirs, 3 files):  17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                           | 1/6 [00:06<00:01,  3.01it/s]\n",
      "Uploading: 0.000%|                                                                                                                | 0/1623925 elapsed<00:00 remaining<?\u001b[A\n",
      "Uploading: 64.570%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                   | 1048576/1623925 elapsed<00:01 remaining<00:00\u001b[A\n",
      "Uploading: 100.000%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1623925/1623925 elapsed<00:02 remaining<00:00\u001b[A\n",
      "Uploading input_example and model_schema:  33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                            | 2/6 [00:08<00:20,  5.08s/it]\n",
      "Uploading: 0.000%|                                                                                                                     | 0/75 elapsed<00:00 remaining<?\u001b[A\n",
      "Uploading: 100.000%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 75/75 elapsed<00:01 remaining<00:00\u001b[A\n",
      "\n",
      "Uploading: 0.000%|                                                                                                                    | 0/484 elapsed<00:00 remaining<?\u001b[A\n",
      "Uploading: 100.000%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 484/484 elapsed<00:01 remaining<00:00\u001b[A\n",
      "Model export complete: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:17<00:00,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created, explore it at https://c.app.hopsworks.ai:443/p/17565/models/query_model/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(name: 'query_model', version: 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample a query example from the query DataFrame\n",
    "query_example = query_df.sample().to_dict(\"records\")\n",
    "\n",
    "# Create a tensorflow model for the query_model in the Model Registry \n",
    "mr_query_model = mr.tensorflow.create_model(\n",
    "    name=\"query_model\",                                           # Name of the model\n",
    "    description=\"Model that generates query embeddings from user features\",  # Description of the model\n",
    "    input_example=query_example,                                  # Example input for the model\n",
    "    model_schema=query_model_schema,                              # Schema of the model\n",
    ")\n",
    "\n",
    "# Save the query_model to the Model Registry\n",
    "mr_query_model.save(\"query_model\")                                # Path to save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4535c5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading model files (2 dirs, 0 files):  17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                           | 1/6 [00:01<00:01,  3.34it/s]\n",
      "Uploading: 0.000%|                                                                                                                 | 0/511357 elapsed<00:00 remaining<?\u001b[A\n",
      "Uploading: 100.000%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 511357/511357 elapsed<00:02 remaining<00:00\u001b[A\n",
      "Uploading model files (2 dirs, 1 files):  17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                           | 1/6 [00:03<00:01,  3.34it/s]\n",
      "Uploading: 0.000%|                                                                                                                     | 0/55 elapsed<00:00 remaining<?\u001b[A\n",
      "Uploading: 100.000%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 55/55 elapsed<00:01 remaining<00:00\u001b[A\n",
      "Uploading model files (2 dirs, 2 files):  17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                           | 1/6 [00:04<00:01,  3.34it/s]\n",
      "Uploading: 0.000%|                                                                                                                    | 0/562 elapsed<00:00 remaining<?\u001b[A\n",
      "Uploading: 100.000%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 562/562 elapsed<00:01 remaining<00:00\u001b[A\n",
      "Uploading model files (2 dirs, 3 files):  17%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                           | 1/6 [00:06<00:01,  3.34it/s]\n",
      "Uploading: 0.000%|                                                                                                                | 0/1607779 elapsed<00:00 remaining<?\u001b[A\n",
      "Uploading: 34.781%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                                                                  | 559203/1607779 elapsed<00:01 remaining<00:02\u001b[A\n",
      "Uploading: 100.000%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1607779/1607779 elapsed<00:02 remaining<00:00\u001b[A\n",
      "Uploading input_example and model_schema:  33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                            | 2/6 [00:08<00:20,  5.03s/it]\n",
      "Uploading: 0.000%|                                                                                                                     | 0/99 elapsed<00:00 remaining<?\u001b[A\n",
      "Uploading: 100.000%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 99/99 elapsed<00:01 remaining<00:00\u001b[A\n",
      "\n",
      "Uploading: 0.000%|                                                                                                                    | 0/563 elapsed<00:00 remaining<?\u001b[A\n",
      "Uploading: 100.000%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 563/563 elapsed<00:01 remaining<00:00\u001b[A\n",
      "Model export complete: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [00:17<00:00,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created, explore it at https://c.app.hopsworks.ai:443/p/17565/models/candidate_model/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(name: 'candidate_model', version: 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the input schema for the candidate_model based on item_df\n",
    "candidate_model_input_schema = Schema(item_df)\n",
    "\n",
    "# Define the output schema for the candidate_model, specifying the shape and type of the output\n",
    "candidate_model_output_schema = Schema([{\n",
    "    \"name\": \"candidate_embedding\",   # Name of the output feature\n",
    "    \"type\": \"float32\",               # Data type of the output feature\n",
    "    \"shape\": [EMB_DIM],              # Shape of the output feature\n",
    "}])\n",
    "\n",
    "# Combine the input and output schemas to create the overall model schema for the candidate_model\n",
    "candidate_model_schema = ModelSchema(\n",
    "    input_schema=candidate_model_input_schema,    # Input schema for the model\n",
    "    output_schema=candidate_model_output_schema,  # Output schema for the model\n",
    ")\n",
    "\n",
    "# Sample a candidate example from the item DataFrame\n",
    "candidate_example = item_df.sample().to_dict(\"records\")\n",
    "\n",
    "# Create a tensorflow model for the candidate_model in the Model Registry\n",
    "mr_candidate_model = mr.tensorflow.create_model(\n",
    "    name=\"candidate_model\",                                        # Name of the model\n",
    "    description=\"Model that generates candidate embeddings from video features\",  # Description of the model\n",
    "    input_example=candidate_example,                              # Example input for the model\n",
    "    model_schema=candidate_model_schema,                          # Schema of the model\n",
    ")\n",
    "\n",
    "# Save the candidate_model to the Model Registry\n",
    "mr_candidate_model.save(\"candidate_model\")                        # Path to save the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657e0ba1",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
